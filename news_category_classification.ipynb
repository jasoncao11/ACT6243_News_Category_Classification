{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Category Classification\n",
    "\n",
    "The goal of this Lab is to explore some of the main scikit-learn tools on a single practical task: analyzing a collection of text documents (newsgroups posts) on twenty different topics.\n",
    "\n",
    "In this Lab we will see how to:\n",
    "\n",
    "- Load the file contents and the categories\n",
    "- Extract feature vectors suitable for machine learning\n",
    "- Training a classifier\n",
    "- Building a pipeline\n",
    "- Parameter tuning using grid search\n",
    "- Evaluation of the performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the 20 newsgroups dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the built-in dataset loader for 20 newsgroups from scikit-learn. In order to get faster execution times for this first example we will work on a partial dataset with only 3 categories out of the 20 available in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the list of files matching those categories as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target_names holds the list of the requested category names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples and the corresponding categories used for training are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = twenty_train.data\n",
    "y_train = twenty_train.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features from text files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform machine learning on text documents, we first need to turn the text content into numerical feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Write code to implement following:\n",
    "- initialize TfidfVectorizer\n",
    "- fit and tranform using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "### START CODE HERE ###\n",
    "# initialize TfidfVectorizer as tfidf_vectorizer\n",
    "tfidf_vectorizer = \n",
    "\n",
    "# fit and tranform using training data \n",
    "X_train_tfidf = \n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our features, we can train a classifier to try to predict the category of a post. Let’s use [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), which is widely regarded as one of the best text classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Write code to implement following:\n",
    "- initialize and train a LogisticRegression classifier as clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "### START CODE HERE ###\n",
    "# initialize and train a LogisticRegression classifier as clf\n",
    "clf = \n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predict the category on new documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "### START CODE HERE ###\n",
    "# transform new documents using the same feature extraction method as before\n",
    "# that is using the fitted tfidf_vectorizer, tranform the new documents\n",
    "X_new_tfidf = \n",
    "# predict the category on new documents \n",
    "predicted = \n",
    "### END CODE HERE ###\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the vectorizer => classifier easier to work with, scikit-learn provides a Pipeline class that behaves like a compound classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Write code to implement following:\n",
    "- construct a pipeline to assemble TfidfVectorizer and LogisticRegression\n",
    "- name the pipeline as text_clf\n",
    "- you will use [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline), check out its documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "### START CODE HERE ###\n",
    "text_clf = \n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning using grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve already encountered some parameters such as ngram_range in the TfidfVectorizer. Classifiers tend to have many parameters as well; e.g., LogisticRegression includes has a regularization parameter C.\n",
    "\n",
    "Instead of tweaking the parameters of the various components of the chain, it is possible to run an exhaustive search of the best parameters on a grid of possible values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Write code to implement following:\n",
    "- try out all classifiers on either words or bigrams and with a regularization parameter of either 1, 0.1 or 0.01 for the LogisticRegression\n",
    "- you will use [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), check out its documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "### START CODE HERE ###\n",
    "parameters = \n",
    "### END CODE HERE ###\n",
    "# n_jobs is to specify how many cpu cores to use, If we give this parameter a value of -1, grid search will detect how many cores are installed and use them all\n",
    "# cv determines the cross-validation splitting strategy\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search instance behaves like a normal scikit-learn model. Let’s perform the search on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more detailed summary of the search is available at gs_clf.cv_results_. The cv_results_ parameter can be easily imported into pandas as a DataFrame for further inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cv_result = pd.DataFrame(gs_clf.cv_results_)\n",
    "cv_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object’s best_score_ and best_params_ attributes store the best mean score and the parameters setting corresponding to that score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test',categories=categories, shuffle=True, random_state=42)\n",
    "X_test = twenty_test.data\n",
    "y_test = twenty_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of calling fit on a GridSearchCV object is a classifier that we can use to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train.target_names[gs_clf.predict(['God is love'])[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Write code to implement following:\n",
    "- predict the category on test data\n",
    "- using [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) to print out the result, check out its documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also print out the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pre = gs_clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_pre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
